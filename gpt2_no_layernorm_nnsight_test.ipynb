{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/dictionary_learning/logan/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained model gpt2 into HookedTransformer\n",
      "Moving model to device:  cpu\n",
      "torch.Size([1, 4, 50257])\n",
      "tensor([25.9575, 27.0594, 23.7760, 24.0054, 25.5462, 23.6517, 26.7588, 25.8552,\n",
      "        27.0049, 25.4789], grad_fn=<SliceBackward0>)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import GPT2LMHeadModel\n",
    "from transformer_lens import HookedTransformer\n",
    "\n",
    "\n",
    "model = GPT2LMHeadModel.from_pretrained(\"apollo-research/gpt2_noLN\").to(\"cpu\")\n",
    "\n",
    "# Undo my hacky LayerNorm removal\n",
    "for block in model.transformer.h:\n",
    "    block.ln_1.weight.data = block.ln_1.weight.data / 1e6\n",
    "    block.ln_1.eps = 1e-5\n",
    "    block.ln_2.weight.data = block.ln_2.weight.data / 1e6\n",
    "    block.ln_2.eps = 1e-5\n",
    "model.transformer.ln_f.weight.data = model.transformer.ln_f.weight.data / 1e6\n",
    "model.transformer.ln_f.eps = 1e-5\n",
    "\n",
    "# Properly replace LayerNorms by Identities\n",
    "class HookedTransformerNoLN(HookedTransformer):\n",
    "    def removeLN(self):\n",
    "        for i in range(len(self.blocks)):\n",
    "            self.blocks[i].ln1 = torch.nn.Identity()\n",
    "            self.blocks[i].ln2 = torch.nn.Identity()\n",
    "        self.ln_final = torch.nn.Identity()\n",
    "\n",
    "hooked_model = HookedTransformerNoLN.from_pretrained(\"gpt2\", hf_model=model, fold_ln=True, center_unembed=False).to(\"cpu\")\n",
    "hooked_model.removeLN()\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "prompt = torch.tensor([1,2,3,4], device=device)\n",
    "logits = hooked_model(prompt)\n",
    "\n",
    "print(logits.shape)\n",
    "print(logits[0, 0, :10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/dictionary_learning/logan/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from nnsight import LanguageModel\n",
    "# import gpt2 tokenizer\n",
    "from transformers import GPT2Tokenizer\n",
    "model_nnsight = LanguageModel(\n",
    "    \"apollo-research/gpt2_noLN\",\n",
    "    device_map = \"cpu\",\n",
    "    tokenizer = GPT2Tokenizer.from_pretrained(\"gpt2\"),\n",
    "    # automodel = GPT2LMHeadModel,\n",
    "    dispatch = True,\n",
    "    # torch_dtype=torch.bfloat16,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Linear(in_features=768, out_features=50257, bias=False)"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_nnsight.lm_head = # new linear layer\n",
    "model_nnsight.lm_head = torch.nn.Linear(768, 50257)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([768, 768])\n",
      "torch.Size([768, 768])\n",
      "torch.Size([768, 768])\n",
      "torch.Size([768, 768])\n",
      "torch.Size([768, 768])\n",
      "torch.Size([768, 768])\n",
      "torch.Size([768, 768])\n",
      "torch.Size([768, 768])\n",
      "torch.Size([768, 768])\n",
      "torch.Size([768, 768])\n",
      "torch.Size([768, 768])\n",
      "torch.Size([768, 768])\n",
      "Weights reassigned successfully for all 12 layers.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from einops import rearrange\n",
    "\n",
    "\n",
    "num_layers = len(model_nnsight.transformer.h)\n",
    "\n",
    "# Reassign embedding weights\n",
    "model_nnsight.transformer.wte.weight.data.copy_(hooked_model.W_E.data)\n",
    "model_nnsight.transformer.wpe.weight.data.copy_(hooked_model.W_pos.data)\n",
    "model_nnsight.lm_head = torch.nn.Linear(768, 50257)\n",
    "model_nnsight.lm_head.weight.data.copy_(hooked_model.W_U.data.t())\n",
    "\n",
    "for layer in range(num_layers):\n",
    "    # Replace layer norms with identity\n",
    "    model_nnsight.transformer.h[layer].ln_1 = torch.nn.Identity()\n",
    "    model_nnsight.transformer.h[layer].ln_2 = torch.nn.Identity()\n",
    "\n",
    "    # Reassign attention weights (Q, K, V)\n",
    "    # q = hooked_model.W_Q[layer].data.reshape(768, 64 * 12)\n",
    "    # k = hooked_model.W_K[layer].data.reshape(768, 64 * 12)\n",
    "    # v = hooked_model.W_V[layer].data.reshape(768, 64 * 12)\n",
    "    q = rearrange(hooked_model.W_Q[layer].data, 'w d l -> d (w l)')\n",
    "    k = rearrange(hooked_model.W_K[layer].data, 'w d l -> d (w l)')\n",
    "    v = rearrange(hooked_model.W_V[layer].data, 'w d l -> d (w l)').T\n",
    "\n",
    "\n",
    "    \n",
    "    # Concatenate Q, K, V\n",
    "    qkv = torch.cat([q, k, v], dim=1)\n",
    "    \n",
    "    # Assign to c_attn\n",
    "    model_nnsight.transformer.h[layer].attn.c_attn.weight.data.copy_(qkv)\n",
    "    \n",
    "    #TODO: verify that the W_O needs to be transposed\n",
    "    # Reassign output projection (W_O to c_proj)\n",
    "    w_o = rearrange(hooked_model.W_O[layer].data, \"w l d -> (w l) d\").T\n",
    "\n",
    "    model_nnsight.transformer.h[layer].attn.c_proj.weight.data.copy_(w_o)\n",
    "    \n",
    "    # Reassign MLP weights\n",
    "    model_nnsight.transformer.h[layer].mlp.c_fc.weight.data.copy_(\n",
    "        hooked_model.W_in[layer].data.reshape(3072, 768).t()\n",
    "    )\n",
    "    # and bias\n",
    "    model_nnsight.transformer.h[layer].mlp.c_fc.bias.data.copy_(\n",
    "        hooked_model.b_in[layer].data\n",
    "    )\n",
    "    model_nnsight.transformer.h[layer].mlp.c_proj.weight.data.copy_(\n",
    "        hooked_model.W_out[layer].data.reshape(768, 3072).t()\n",
    "    )\n",
    "    # and bias\n",
    "    model_nnsight.transformer.h[layer].mlp.c_proj.bias.data.copy_(\n",
    "        hooked_model.b_out[layer].data\n",
    "    )\n",
    "# Replace final layer norm with identity\n",
    "model_nnsight.transformer.ln_f = torch.nn.Identity()\n",
    "\n",
    "print(f\"Weights reassigned successfully for all {num_layers} layers.\")\n",
    "\n",
    "# Usage\n",
    "# reassign_weights(hooked_model, model_nnsight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ True, False, False,  ..., False, False, False],\n",
       "        [False,  True, False,  ..., False, False, False],\n",
       "        [False, False,  True,  ..., False, False, False],\n",
       "        ...,\n",
       "        [False, False, False,  ...,  True, False, False],\n",
       "        [False, False, False,  ..., False,  True, False],\n",
       "        [False, False, False,  ..., False, False,  True]])"
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hooked_model.W_O[layer].shape\n",
    "w_o = rearrange(hooked_model.W_O[layer].data, \"w l d -> (w l) d\")\n",
    "w_o.T == hooked_model.W_O[layer].data.reshape(768, 768)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0142,  0.0025, -0.0053,  ...,  0.0020, -0.0021, -0.0142],\n",
       "        [ 0.0008, -0.0083, -0.0019,  ..., -0.0025, -0.0029, -0.0009],\n",
       "        [ 0.0077, -0.0039,  0.0032,  ..., -0.0027,  0.0036, -0.0049],\n",
       "        ...,\n",
       "        [ 0.0025,  0.0060,  0.0022,  ..., -0.0117,  0.0016,  0.0092],\n",
       "        [-0.0054,  0.0048,  0.0004,  ..., -0.0070, -0.0028,  0.0018],\n",
       "        [ 0.0096,  0.0027, -0.0016,  ...,  0.0030, -0.0039, -0.0040]])"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from einops import rearrange\n",
    "tt = hooked_model.W_Q[layer].data\n",
    "q_w = rearrange(tt, 'w d l -> d (w l)')\n",
    "q = hooked_model.W_Q[layer].data.reshape(768, 64 * 12)\n",
    "q_w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([12, 768, 64]), torch.Size([12, 768, 64]))"
      ]
     },
     "execution_count": 219,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hooked_model.W_Q[layer].data.shape, hooked_model.W_V[layer].data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_nnsight.tokenizer.pad_token = model_nnsight.tokenizer.eos_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[-0.1718,  1.5577,  1.8667,  ..., -1.3739,  5.0515, -5.4432],\n",
      "         [-0.6355,  0.7799,  1.6813,  ..., -0.8211,  4.3663, -4.2849],\n",
      "         [-0.4399,  1.3715,  1.9858,  ..., -1.1645,  3.6269, -2.7695],\n",
      "         [ 0.0286,  0.8474,  1.3604,  ..., -0.9685,  3.2331, -2.9667]]])\n"
     ]
    }
   ],
   "source": [
    "# with model_nnsight.trace(\"The Eiffel Tower is in the city of\") as runner:\n",
    "with torch.no_grad():\n",
    "    with model_nnsight.trace(prompt) as runner:\n",
    "        embedding = model_nnsight.transformer.wte.output.save()\n",
    "        layer_1_output = model_nnsight.transformer.h[0].ln_1.output.save()\n",
    "        attn_mid = model_nnsight.transformer.h[0].attn.c_attn.output.save()\n",
    "        attn_out = model_nnsight.transformer.h[0].attn.c_proj.output.save()\n",
    "        logits2 = model_nnsight.lm_head.output.save()\n",
    "\n",
    "print(attn_out)\n",
    "# print(embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(True)"
      ]
     },
     "execution_count": 243,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(cache[\"blocks.0.hook_resid_pre\"] == layer_1_output).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[False, False, False,  ..., False, False, False],\n",
       "         [False, False, False,  ..., False, False, False],\n",
       "         [False, False, False,  ..., False, False, False],\n",
       "         [False, False, False,  ..., False, False, False]]])"
      ]
     },
     "execution_count": 244,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(cache[\"blocks.0.hook_attn_out\"] == attn_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[ 1.7667,  0.8346, -0.4114,  ..., -0.1989,  0.0705,  0.0129],\n",
       "          [ 0.7096, -0.2735, -0.5014,  ..., -0.1504,  0.1146,  0.1199],\n",
       "          [-0.8842,  0.2575, -0.2667,  ..., -0.0960,  0.0550,  0.0929],\n",
       "          [-0.1350,  0.2363, -0.2860,  ..., -0.0152, -0.0279,  0.1651]]]),\n",
       " tensor([[[-0.1718,  1.5577,  1.8667,  ..., -1.3739,  5.0515, -5.4432],\n",
       "          [-0.6355,  0.7799,  1.6813,  ..., -0.8211,  4.3663, -4.2849],\n",
       "          [-0.4399,  1.3715,  1.9858,  ..., -1.1645,  3.6269, -2.7695],\n",
       "          [ 0.0286,  0.8474,  1.3604,  ..., -0.9685,  3.2331, -2.9667]]]))"
      ]
     },
     "execution_count": 245,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cache[\"blocks.0.hook_attn_out\"], attn_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn_q, nn_k, nn_v = attn_mid.chunk(3, dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_q = cache[\"blocks.0.attn.hook_q\"].reshape(1, 4, 12*64)\n",
    "t_k = cache[\"blocks.0.attn.hook_k\"].reshape(1, 4, 12*64)\n",
    "t_v = cache[\"blocks.0.attn.hook_v\"].reshape(1, 4, 12*64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[-4.8225e-02, -3.1213e-01,  4.0030e-01,  ..., -1.2137e+00,\n",
       "           -1.0406e-01,  3.6115e-01],\n",
       "          [ 2.9163e-01,  8.9444e-04,  1.9521e-01,  ..., -4.4900e-01,\n",
       "            9.9427e-02, -7.0002e-01],\n",
       "          [-2.4940e-01, -2.8410e-02, -3.4262e-03,  ..., -1.2382e-01,\n",
       "            2.7189e-01, -8.3504e-01],\n",
       "          [-6.9130e-02, -3.5274e-01, -1.0790e-01,  ..., -1.8287e-01,\n",
       "            1.0387e-01, -8.1425e-01]]]),\n",
       " tensor([[[ 0.3170,  0.1050,  0.1032,  ...,  0.0614, -0.1157,  0.1413],\n",
       "          [-0.1031,  0.2391, -0.1225,  ..., -0.0869,  0.4240,  0.1991],\n",
       "          [ 0.0802, -0.1100,  0.1615,  ...,  0.1792,  0.0789,  0.3793],\n",
       "          [ 0.0471,  0.0282,  0.0530,  ..., -0.1254,  0.1734,  0.2399]]]))"
      ]
     },
     "execution_count": 251,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn_v, t_v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(True), tensor(True), tensor(False))"
      ]
     },
     "execution_count": 250,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(nn_q ==t_q).all(), (nn_k == t_k).all(), (nn_v == t_v).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 1.7667,  0.8346, -0.4114,  ..., -0.1989,  0.0705,  0.0129],\n",
       "         [ 0.7096, -0.2735, -0.5014,  ..., -0.1504,  0.1146,  0.1199],\n",
       "         [-0.8842,  0.2575, -0.2667,  ..., -0.0960,  0.0550,  0.0929],\n",
       "         [-0.1350,  0.2363, -0.2860,  ..., -0.0152, -0.0279,  0.1651]]])"
      ]
     },
     "execution_count": 249,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cache[\"blocks.0.hook_attn_out\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[  86.2191,   95.8736,    8.8613,  ...,  -66.9563,  -51.0069,\n",
      "            68.8289],\n",
      "         [ 276.7668,  329.2255,   60.9252,  ..., -353.2906, -310.6661,\n",
      "           226.2671],\n",
      "         [ 304.9153,  355.0207,  104.5744,  ..., -398.3969, -337.3764,\n",
      "           256.1240],\n",
      "         [ 265.2124,  299.4694,   95.2499,  ..., -390.3568, -341.6725,\n",
      "           231.0227]]], grad_fn=<ViewBackward0>)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(True)"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits, cache = hooked_model.run_with_cache(prompt)\n",
    "print(logits)\n",
    "(cache[\"hook_embed\"] == embedding).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[-0.0989, -0.0314,  0.0315,  ..., -0.1332,  0.0162,  0.0412],\n",
       "         [ 0.0224, -0.0670,  0.0560,  ...,  0.0702, -0.0031,  0.0405],\n",
       "         [-0.0920,  0.0471,  0.1977,  ...,  0.0885, -0.1139, -0.0840],\n",
       "         ...,\n",
       "         [-0.0403, -0.0671,  0.0289,  ...,  0.0636,  0.0674, -0.0481],\n",
       "         [ 0.1565,  0.0520,  0.0939,  ..., -0.1061,  0.0661, -0.0163],\n",
       "         [ 0.0319, -0.0337,  0.0541,  ...,  0.0057,  0.1539,  0.1086]]),\n",
       " tensor([[-0.0989, -0.0314,  0.0315,  ..., -0.1332,  0.0162,  0.0412],\n",
       "         [ 0.0224, -0.0670,  0.0560,  ...,  0.0702, -0.0031,  0.0405],\n",
       "         [-0.0920,  0.0471,  0.1977,  ...,  0.0885, -0.1139, -0.0840],\n",
       "         ...,\n",
       "         [-0.0403, -0.0671,  0.0289,  ...,  0.0636,  0.0674, -0.0481],\n",
       "         [ 0.1565,  0.0520,  0.0939,  ..., -0.1061,  0.0661, -0.0163],\n",
       "         [ 0.0319, -0.0337,  0.0541,  ...,  0.0057,  0.1539,  0.1086]]))"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hooked_model.W_E.data, model_nnsight.transformer.wte.weight.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0989, -0.0314,  0.0315,  ..., -0.1332,  0.0162,  0.0412],\n",
       "        [ 0.0224, -0.0670,  0.0560,  ...,  0.0702, -0.0031,  0.0405],\n",
       "        [-0.0920,  0.0471,  0.1977,  ...,  0.0885, -0.1139, -0.0840],\n",
       "        ...,\n",
       "        [-0.0403, -0.0671,  0.0289,  ...,  0.0636,  0.0674, -0.0481],\n",
       "        [ 0.1565,  0.0520,  0.0939,  ..., -0.1061,  0.0661, -0.0163],\n",
       "        [ 0.0319, -0.0337,  0.0541,  ...,  0.0057,  0.1539,  0.1086]])"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_nnsight.transformer.wte.weight.data.copy_(hooked_model.W_E.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[25.9575, 27.0594, 23.7760,  ..., 17.6671, 18.9357, 26.1557],\n",
       "          [24.1554, 25.3277, 22.7836,  ..., 11.8491, 13.6343, 20.8459],\n",
       "          [24.2269, 24.8723, 26.2722,  ..., 11.1776, 14.7698, 21.2890],\n",
       "          [20.3492, 20.0784, 22.7114,  ...,  7.8679, 10.2955, 17.9141]]],\n",
       "        grad_fn=<ViewBackward0>),\n",
       " tensor([[[  1820.8167,  -4156.5581, -10981.4482,  ...,   6701.2451,\n",
       "            10023.3066,  -3584.3672],\n",
       "          [ 12723.0762,   4954.4199,  -3065.8164,  ...,  15503.4863,\n",
       "            13852.7109,   4862.6143],\n",
       "          [ 23775.0645,  15293.0449,   9126.6895,  ...,  25649.3242,\n",
       "            21742.1602,  18540.6562],\n",
       "          [ 20258.9121,  13101.9219,   5408.4473,  ...,  19866.7871,\n",
       "            16596.6367,  13572.1055]]], grad_fn=<UnsafeViewBackward0>))"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits, logits2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPT2LMHeadModel(\n",
       "  (transformer): GPT2Model(\n",
       "    (wte): Embedding(50257, 768)\n",
       "    (wpe): Embedding(1024, 768)\n",
       "    (drop): Dropout(p=0, inplace=False)\n",
       "    (h): ModuleList(\n",
       "      (0-11): 12 x GPT2Block(\n",
       "        (ln_1): Identity()\n",
       "        (attn): GPT2SdpaAttention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0, inplace=False)\n",
       "        )\n",
       "        (ln_2): Identity()\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (ln_f): Identity()\n",
       "  )\n",
       "  (lm_head): Linear(in_features=768, out_features=50257, bias=False)\n",
       "  (generator): WrapperModule()\n",
       ")"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_nnsight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_nnsight.transformer.wte.weight.data = hooked_model.W_E.data\n",
    "model_nnsight.transformer.wpe.weight.data = hooked_model.W_pos.data\n",
    "model_nnsight.lm_head.weight.data = hooked_model.W_U.data.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([12, 768, 3072]),\n",
       " torch.Size([12, 3072, 768]),\n",
       " torch.Size([768, 3072]),\n",
       " torch.Size([3072, 768]))"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ln Done already\n",
    "# Attn\n",
    "hooked_model.W_in.shape, hooked_model.W_out.shape, model_nnsight.transformer.h[0].mlp.c_fc.weight.data.shape, model_nnsight.transformer.h[0].mlp.c_proj.weight.data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1024, 768]), torch.Size([1024, 768]))"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hooked_model.W_pos.shape, model_nnsight.transformer.wpe.weight.data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([12, 768, 64]), torch.Size([768, 2304]))"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hooked_model.W_K[0].data.shape, model_nnsight.transformer.h[0].attn.c_attn.weight.data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([768, 768])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_nnsight.transformer.h[0].attn.c_proj.weight.data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in range(len(self.blocks)):\n",
    "#     self.blocks[i].ln1 = torch.nn.Identity()\n",
    "#     self.blocks[i].ln2 = torch.nn.Identity()\n",
    "# self.ln_final = torch.nn.Identity()\n",
    "for i in range(len(model_nnsight.transformer.h)):\n",
    "    model_nnsight.transformer.h[i].ln_1 = torch.nn.Identity()\n",
    "    model_nnsight.transformer.h[i].ln_2 = torch.nn.Identity()\n",
    "model_nnsight.transformer.ln_f = torch.nn.Identity()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Identity()"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_nnsight.transformer.h[0].ln_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPT2LMHeadModel(\n",
       "  (transformer): GPT2Model(\n",
       "    (wte): Embedding(50257, 768)\n",
       "    (wpe): Embedding(1024, 768)\n",
       "    (drop): Dropout(p=0, inplace=False)\n",
       "    (h): ModuleList(\n",
       "      (0-11): 12 x GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2SdpaAttention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (lm_head): Linear(in_features=768, out_features=50257, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 4, 50257])\n",
      "tensor([25.9575, 27.0594, 23.7760, 24.0054, 25.5462, 23.6517, 26.7588, 25.8552,\n",
      "        27.0049, 25.4789], grad_fn=<SliceBackward0>)\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "prompt = torch.tensor([1,2,3,4], device=device)\n",
    "logits = hooked_model(prompt)\n",
    "\n",
    "print(logits.shape)\n",
    "print(logits[0, 0, :10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "HookedTransformerNoLN(\n",
       "  (embed): Embed()\n",
       "  (hook_embed): HookPoint()\n",
       "  (pos_embed): PosEmbed()\n",
       "  (hook_pos_embed): HookPoint()\n",
       "  (blocks): ModuleList(\n",
       "    (0-11): 12 x TransformerBlock(\n",
       "      (ln1): Identity()\n",
       "      (ln2): Identity()\n",
       "      (attn): Attention(\n",
       "        (hook_k): HookPoint()\n",
       "        (hook_q): HookPoint()\n",
       "        (hook_v): HookPoint()\n",
       "        (hook_z): HookPoint()\n",
       "        (hook_attn_scores): HookPoint()\n",
       "        (hook_pattern): HookPoint()\n",
       "        (hook_result): HookPoint()\n",
       "      )\n",
       "      (mlp): MLP(\n",
       "        (hook_pre): HookPoint()\n",
       "        (hook_post): HookPoint()\n",
       "      )\n",
       "      (hook_attn_in): HookPoint()\n",
       "      (hook_q_input): HookPoint()\n",
       "      (hook_k_input): HookPoint()\n",
       "      (hook_v_input): HookPoint()\n",
       "      (hook_mlp_in): HookPoint()\n",
       "      (hook_attn_out): HookPoint()\n",
       "      (hook_mlp_out): HookPoint()\n",
       "      (hook_resid_pre): HookPoint()\n",
       "      (hook_resid_mid): HookPoint()\n",
       "      (hook_resid_post): HookPoint()\n",
       "    )\n",
       "  )\n",
       "  (ln_final): Identity()\n",
       "  (unembed): Unembed()\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hooked_model"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "logan",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
